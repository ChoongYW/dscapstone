}
splitLine
i
close(con)
con <- file(twitter.txt)
open(con)
twitter.list <- list()
i <- 0
while (length(oneLine <- readLines(con, n=1)) > 0) {
i <- i + 1
splitLine <- unlist(strsplit(oneLine, split=" "))
twitter.list[[i]] <- splitLine
}
con <- file(twitter.txt, open="r")
open(con)
twitter.list <- list()
i <- 0
while (length(oneLine <- readLines(con, n=1, warn=FALSE)) > 0) {
i <- i + 1
# splitLine <- unlist(strsplit(oneLine, split=" "))
twitter.list[[i]] <- oneLine
}
install.packages("R.utils")
library(R.utils)
countLines(twitter.txt)
setwd("..")
setwd("capstone")
system("ls")
pwd()
getwd()
setwd("..")
setwd("dscapstone")
setwd("capstone/dscapstone")
orig <- getwd()
setwd("../final")
setwd("en_US")
setwd(orig)
system("wc -w *.txt")
if (!file.exists("../final")) {
fileUrl <- "https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip"
download.file(fileUrl, destfile = "../swiftkey.zip")
unzip("../swiftkey.zip")
}
orig.wd <- getwd() # save working dir, to return to later
setwd("../final/en_US")
system("ls -alh")
numwords <- system("wc -w *.txt", intern=TRUE)
numwords
numlines <- system("wc -l *.txt", intern=TRUE)
numlines
longest <- system("wc -L *.txt", intern=TRUE)
longest
setwd(orig.wd)
blog.numwords <- gsub('[^0-9]', '', numwords[1])
news.numwords <- gsub('[^0-9]', '', numwords[2])
twit.numwords <- gsub('[^0-9]', '', numwords[3])
blog.numlines <- gsub('[^0-9]', '', numlines[1])
news.numlines <- gsub('[^0-9]', '', numlines[2])
twit.numlines <- gsub('[^0-9]', '', numlines[3])
# length of longest line for each dataset
blog.longest  <- gsub('[^0-9]', '',  longest[1])
news.longest  <- gsub('[^0-9]', '',  longest[2])
twit.longest  <- gsub('[^0-9]', '',  longest[3])
round(blog.numwords/blog.numlines)
round(as.numeric(blog.numwords)/as.numeric(blog.numlines))
round(as.numeric(news.numwords)/as.numeric(news.numlines))
blog.numwords <- as.numeric(gsub('[^0-9]', '', numwords[1]))
news.numwords <- as.numeric(gsub('[^0-9]', '', numwords[2]))
twit.numwords <- as.numeric(gsub('[^0-9]', '', numwords[3]))
# number of lines for each dataset
blog.numlines <- as.numeric(gsub('[^0-9]', '', numlines[1]))
news.numlines <- as.numeric(gsub('[^0-9]', '', numlines[2]))
twit.numlines <- as.numeric(gsub('[^0-9]', '', numlines[3]))
# length of longest line for each dataset
blog.longest  <- as.numeric(gsub('[^0-9]', '',  longest[1]))
news.longest  <- as.numeric(gsub('[^0-9]', '',  longest[2]))
twit.longest  <- as.numeric(gsub('[^0-9]', '',  longest[3]))
# create and display summary table
blog.stats <- c(blog.numwords, blog.numlines, blog.longest,
round(blog.numwords/blog.numlines))
news.stats <- c(news.numwords, news.numlines, news.longest,
round(news.numwords/news.numlines))
twit.stats <- c(twit.numwords, twit.numlines, twit.longest,
round(twit.numwords/twit.numlines))
data.stats <- data.frame(rbind(blog.stats, news.stats, twit.stats))
names(data.stats) <- c("Total word count",
"Total line count",
"Number of words in longest line",
"Average words per line")
data.stats
SampleTxt <- function(infile, outfile, seed, inlines, percent) {
conn.in <- file(infile,"r")
conn.out <- file(outfile,"w")
# for each line, flip a coin to decide whether to put it in sample
set.seed(seed)
in.sample <- rbinom(n=inlines, size=1, prob=percent)
i <- 0
num.out <- 0  # number of lines written out to subsample
for (i in 1:inlines) {
# read in one line at a time
currLine <- readLines(conn.in, n=1, encoding="UTF-8", skipNul=TRUE)
# if reached end of file, close all conns
if (length(currLine) == 0) {
close(conn.out)
close(conn.in)
# return number of lines written out to subsample
return(num.out)
}
# while not end of file, write out the selected line to file
if (in.sample[i] == 1) {
writeLines(currLine, conn.out)
num.out <- num.out + 1
}
}
}
datalist <- c("../final/en_US/en_US.blogs.txt",
"../final/en_US/en_US.news.txt",
"../final/en_US/en_US.twitter.txt")
mypercent <- 0.05
myseed <- 60637
if (!file.exists("./blog.sample.txt")) {
blog.samplesize <- SampleTxt(datalist[1], "blog.sample.txt", myseed,
blog.numlines, mypercent)
}
if (!file.exists("./blog.sample.txt")) {
blog.samplesize <- SampleTxt(datalist[1], "blog.sample.txt", myseed,
blog.numlines, mypercent)
}
orig.wd <- getwd() # save working dir, to return to later
setwd("../final/en_US")
system("ls")
numwords <- system("wc -w *.txt", intern=TRUE)  # intern=TRUE to return output
numlines <- system("wc -l *.txt", intern=TRUE)
longest <- system("wc -L *.txt", intern=TRUE)
setwd(orig.wd)
numwors
numwords
numwords[1]
numlines
longest
blog.numwords <- as.numeric(gsub('[^0-9]', '', numwords[1]))
news.numwords <- as.numeric(gsub('[^0-9]', '', numwords[2]))
twit.numwords <- as.numeric(gsub('[^0-9]', '', numwords[3]))
# number of lines for each dataset
blog.numlines <- as.numeric(gsub('[^0-9]', '', numlines[1]))
news.numlines <- as.numeric(gsub('[^0-9]', '', numlines[2]))
twit.numlines <- as.numeric(gsub('[^0-9]', '', numlines[3]))
# length of longest line for each dataset
blog.longest  <- as.numeric(gsub('[^0-9]', '',  longest[1]))
news.longest  <- as.numeric(gsub('[^0-9]', '',  longest[2]))
twit.longest  <- as.numeric(gsub('[^0-9]', '',  longest[3]))
blog.numwors
blog.numwords
blog.numlines
blog.longest
news.numwords
news.numlines
news.longest
twit.longest
twit.numwords
twit.numlines
class(twit.numlines)
blog.stats <- c(blog.numwords, blog.numlines, blog.longest,
round(blog.numwords/blog.numlines))
blog.stats
news.stats <- c(news.numwords, news.numlines, news.longest,
round(news.numwords/news.numlines))
twit.stats <- c(twit.numwords, twit.numlines, twit.longest,
round(twit.numwords/twit.numlines))
news.stats
class(news.stats)
data.stats <- data.frame(rbind(blog.stats, news.stats, twit.stats))
data.stats
names(data.stats) <- c("Total word count",
"Total line count",
"Number of words in longest line",
"Average words per line")
data.stats
if (!file.exists("../final")) {
fileUrl <- "https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip"
download.file(fileUrl, destfile = "../swiftkey.zip")
unzip("../swiftkey.zip")
}
orig.wd <- getwd() # save working dir, to return to later
setwd("../final/en_US")
system("ls")
numwords <- system("wc -w *.txt", intern=TRUE)  # intern=TRUE to return output
numlines <- system("wc -l *.txt", intern=TRUE)
longest <- system("wc -L *.txt", intern=TRUE)
setwd(orig.wd)  # return to original working dir, ie. the parent of /final
# number of words for each dataset
blog.numwords <- as.numeric(gsub('[^0-9]', '', numwords[1]))
news.numwords <- as.numeric(gsub('[^0-9]', '', numwords[2]))
twit.numwords <- as.numeric(gsub('[^0-9]', '', numwords[3]))
# number of lines for each dataset
blog.numlines <- as.numeric(gsub('[^0-9]', '', numlines[1]))
news.numlines <- as.numeric(gsub('[^0-9]', '', numlines[2]))
twit.numlines <- as.numeric(gsub('[^0-9]', '', numlines[3]))
# length of longest line for each dataset
blog.longest  <- as.numeric(gsub('[^0-9]', '',  longest[1]))
news.longest  <- as.numeric(gsub('[^0-9]', '',  longest[2]))
twit.longest  <- as.numeric(gsub('[^0-9]', '',  longest[3]))
# create and display summary table
blog.stats <- c(blog.numwords, blog.numlines, blog.longest,
round(blog.numwords/blog.numlines))
news.stats <- c(news.numwords, news.numlines, news.longest,
round(news.numwords/news.numlines))
twit.stats <- c(twit.numwords, twit.numlines, twit.longest,
round(twit.numwords/twit.numlines))
data.stats <- data.frame(rbind(blog.stats, news.stats, twit.stats))
names(data.stats) <- c("Total word count",
"Total line count",
"Number of words in longest line",
"Average words per line")
data.stats
class(blog.numlines)
SampleTxt <- function(infile, outfile, seed, inlines, percent) {
conn.in <- file(infile,"r")
conn.out <- file(outfile,"w")
# for each line, flip a coin to decide whether to put it in sample
set.seed(seed)
in.sample <- rbinom(n=inlines, size=1, prob=percent)
i <- 0
# num.out <- 0  # number of lines written out to subsample
for (i in 1:inlines) {
# read in one line at a time
currLine <- readLines(conn.in, n=1, encoding="UTF-8", skipNul=TRUE)
# if reached end of file, close all conns
if (length(currLine) == 0) {
close(conn.out)
close(conn.in)
# return number of lines written out to subsample
# return(num.out)
}
# while not end of file, write out the selected line to file
if (in.sample[i] == 1) {
writeLines(currLine, conn.out)
# num.out <- num.out + 1
}
}
}
datalist <- c("../final/en_US/en_US.blogs.txt",
"../final/en_US/en_US.news.txt",
"../final/en_US/en_US.twitter.txt")
mypercent <- 0.05
myseed <- 60637
datalist <- c("../final/en_US/en_US.blogs.txt",
"../final/en_US/en_US.news.txt",
"../final/en_US/en_US.twitter.txt")
mypercent <- 0.01
myseed <- 60637
if (!file.exists("./blog.sample.txt")) {
SampleTxt(datalist[1], "blog.sample.txt", myseed, blog.numlines, mypercent)
}
mypercent <- 0.05
SampleTxt <- function(infile, outfile, seed, inlines, percent) {
conn.in <- file(infile,"r")
conn.out <- file(outfile,"w")
# for each line, flip a coin to decide whether to put it in sample
set.seed(seed)
in.sample <- rbinom(n=inlines, size=1, prob=percent)
i <- 0
# num.out <- 0  # number of lines written out to subsample
for (i in 1:inlines+1) {
# read in one line at a time
currLine <- readLines(conn.in, n=1, encoding="UTF-8", skipNul=TRUE)
# if reached end of file, close all conns
if (length(currLine) == 0) {
close(conn.out)
close(conn.in)
# return number of lines written out to subsample
# return(num.out)
}
# while not end of file, write out the selected line to file
if (in.sample[i] == 1) {
writeLines(currLine, conn.out)
# num.out <- num.out + 1
}
}
}
mypercent <- 0.05
myseed <- 60637
if (!file.exists("./news.sample.txt")) {
SampleTxt(datalist[2], "news.sample.txt", myseed, news.numlines, mypercent)
}
if (!file.exists("./blog.sample.txt")) {
SampleTxt(datalist[1], "blog.sample.txt", myseed, blog.numlines, mypercent)
}
SampleTxt <- function(infile, outfile, seed, inlines, percent) {
conn.in <- file(infile,"r")
conn.out <- file(outfile,"w")
# for each line, flip a coin to decide whether to put it in sample
set.seed(seed)
in.sample <- rbinom(n=inlines, size=1, prob=percent)
i <- 0
num.out <- 0  # number of lines written out to subsample
for (i in 1:inlines+1) {
# read in one line at a time
currLine <- readLines(conn.in, n=1, encoding="UTF-8", skipNul=TRUE)
# if reached end of file, close all conns
if (length(currLine) == 0) {
close(conn.out)
close(conn.in)
# return number of lines written out to subsample
return(num.out)
}
# while not end of file, write out the selected line to file
if (in.sample[i] == 1) {
writeLines(currLine, conn.out)
num.out <- num.out + 1
}
}
}
close("blog.sample.txt")
close(file("blog.sample.txt"))
close(file("../final/en_US/en_US.blogs.txt"))
if (!file.exists("./news.sample.txt")) {
SampleTxt(datalist[2], "news.sample.txt", myseed, news.numlines, mypercent)
}
SampleTxt <- function(infile, outfile, seed, inlines, percent) {
conn.in <- file(infile,"r")
conn.out <- file(outfile,"w")
# for each line, flip a coin to decide whether to put it in sample
set.seed(seed)
in.sample <- rbinom(n=inlines, size=1, prob=percent)
i <- 0
num.out <- 0  # number of lines written out to subsample
for (i in 1:(inlines+1)) {
# read in one line at a time
currLine <- readLines(conn.in, n=1, encoding="UTF-8", skipNul=TRUE)
# if reached end of file, close all conns
if (length(currLine) == 0) {
close(conn.out)
close(conn.in)
# return number of lines written out to subsample
return(num.out)
}
# while not end of file, write out the selected line to file
if (in.sample[i] == 1) {
writeLines(currLine, conn.out)
num.out <- num.out + 1
}
}
}
if (!file.exists("./blog.sample.txt")) {
SampleTxt(datalist[1], "blog.sample.txt", myseed, blog.numlines, mypercent)
}
news.numlines
if (!file.exists("./news.sample.txt")) {
SampleTxt(datalist[2], "news.sample.txt", myseed, news.numlines, mypercent)
}
?readLines
SampleTxt <- function(infile, outfile, seed, inlines, percent) {
conn.in <- file(infile,"r",encoding="UTF-8")
conn.out <- file(outfile,"w")
# for each line, flip a coin to decide whether to put it in sample
set.seed(seed)
in.sample <- rbinom(n=inlines, size=1, prob=percent)
i <- 0
num.out <- 0  # number of lines written out to subsample
for (i in 1:(inlines+1)) {
# read in one line at a time
currLine <- readLines(conn.in, n=1, skipNul=TRUE)
# if reached end of file, close all conns
if (length(currLine) == 0) {
close(conn.out)
close(conn.in)
# return number of lines written out to subsample
return(num.out)
}
# while not end of file, write out the selected line to file
if (in.sample[i] == 1) {
writeLines(currLine, conn.out)
num.out <- num.out + 1
}
}
}
if (!file.exists("./news.sample.txt")) {
SampleTxt(datalist[2], "news.sample.txt", myseed, news.numlines, mypercent)
}
Sys.getlocale()
SampleTxt <- function(infile, outfile, seed, inlines, percent, readtype) {
conn.in <- file(infile, readtype)  # readtype = "r" or "rb"
conn.out <- file(outfile,"w")
# for each line, flip a coin to decide whether to put it in sample
set.seed(seed)
in.sample <- rbinom(n=inlines, size=1, prob=percent)
i <- 0
num.out <- 0  # number of lines written out to subsample
for (i in 1:(inlines+1)) {
# read in one line at a time
currLine <- readLines(conn.in, n=1, encoding="UTF-8", skipNul=TRUE)
# if reached end of file, close all conns
if (length(currLine) == 0) {
close(conn.out)
close(conn.in)
# return number of lines written out to subsample
return(num.out)
}
# while not end of file, write out the selected line to file
if (in.sample[i] == 1) {
writeLines(currLine, conn.out)
num.out <- num.out + 1
}
}
}
if (!file.exists("./news.sample.txt")) {
SampleTxt(datalist[2], "news.sample.txt", myseed, news.numlines, mypercent, "rb")
}
if (!file.exists("./twit.sample.txt")) {
SampleTxt(datalist[3], "twit.sample.txt", myseed, twit.numlines, mypercent, "r")
}
data.stats
sample.numwords <- system("wc -w *.sample.txt", intern=TRUE)
sample.numlines <- system("wc -l *.sample.txt", intern=TRUE)
sample.longest <- system("wc -L *.sample.txt", intern=TRUE)
# number of words for each dataset
blog.sample.numwords <- as.numeric(gsub('[^0-9]', '', numwords[1]))
news.sample.numwords <- as.numeric(gsub('[^0-9]', '', numwords[2]))
twit.sample.numwords <- as.numeric(gsub('[^0-9]', '', numwords[3]))
# number of lines for each dataset
blog.sample.numlines <- as.numeric(gsub('[^0-9]', '', numlines[1]))
news.sample.numlines <- as.numeric(gsub('[^0-9]', '', numlines[2]))
twit.sample.numlines <- as.numeric(gsub('[^0-9]', '', numlines[3]))
# length of longest line for each dataset
blog.sample.longest  <- as.numeric(gsub('[^0-9]', '',  longest[1]))
news.sample.longest  <- as.numeric(gsub('[^0-9]', '',  longest[2]))
twit.sample.longest  <- as.numeric(gsub('[^0-9]', '',  longest[3]))
# create and display summary table
blog.sample.stats <- c(blog.sample.numwords, blog.sample.numlines, blog.sample.longest,
round(blog.sample.numwords/blog.sample.numlines))
news.sample.stats <- c(news.sample.numwords, news.sample.numlines, news.sample.longest,
round(news.sample.numwords/news.sample.numlines))
twit.sample.stats <- c(twit.sample.numwords, twit.sample.numlines, twit.sample.longest,
round(twit.sample.numwords/twit.sample.numlines))
sample.stats <- data.frame(rbind(blog.sample.stats,
news.sample.stats,
twit.sample.stats))
names(sample.stats) <- c("Sample word count",
"Sample line count",
"Number of words in longest line",
"Average words per line")
sample.stats
blog.sample.numwords <- as.numeric(gsub('[^0-9]', '', sample.numwords[1]))
news.sample.numwords <- as.numeric(gsub('[^0-9]', '', sample.numwords[2]))
twit.sample.numwords <- as.numeric(gsub('[^0-9]', '', sample.numwords[3]))
# number of lines for each dataset
blog.sample.numlines <- as.numeric(gsub('[^0-9]', '', sample.numlines[1]))
news.sample.numlines <- as.numeric(gsub('[^0-9]', '', sample.numlines[2]))
twit.sample.numlines <- as.numeric(gsub('[^0-9]', '', sample.numlines[3]))
# length of longest line for each dataset
blog.sample.longest  <- as.numeric(gsub('[^0-9]', '',  sample.longest[1]))
news.sample.longest  <- as.numeric(gsub('[^0-9]', '',  sample.longest[2]))
twit.sample.longest  <- as.numeric(gsub('[^0-9]', '',  sample.longest[3]))
blog.sample.stats <- c(blog.sample.numwords, blog.sample.numlines, blog.sample.longest,
round(blog.sample.numwords/blog.sample.numlines))
news.sample.stats <- c(news.sample.numwords, news.sample.numlines, news.sample.longest,
round(news.sample.numwords/news.sample.numlines))
twit.sample.stats <- c(twit.sample.numwords, twit.sample.numlines, twit.sample.longest,
round(twit.sample.numwords/twit.sample.numlines))
sample.stats <- data.frame(rbind(blog.sample.stats,
news.sample.stats,
twit.sample.stats))
sample.stats
blog.sample.numlines/blog.numlines
news.sample.numlines/news.numlines
twit.sample.numlines/twit.numlines
blog.mini <- readLines("./blog.sample.txt")
class(blog.mini)
blog.mini[1]
library(tm)
# build a corpus, specifying the source as a character vector
blog.corpus <- Corpus(VectorSource(blog.mini))
install.packages("tm")
library(tm)
library(tm)
# build a corpus, specifying the vector source as a character vector
blog.corpus <- Corpus(VectorSource(blog.mini))
blog.corpus <- tm_map(blog.corpus, content_transformer(tolower))
# remove numbers
blog.corpus <- tm_map(blog.corpus, content_transformer(removeNumbers))
blog.corpus <- tm_map(blog.corpus, content_transformer(removePunctuation))
# remove URLs
removeURL <- function(x) {
gsub("http[[:alnum:]]", "", x)  # won't work with some links e.g. bit.ly
}
blog.corpus <- tm_map(blog.corpus, content_transformer(removeURL))
inspect(blog.corpus[1])
blog.tdm <- TermDocumentMatrix(blog.corpus)
inspect(blog.tdm[1:5, ])
blog.tdm
inspect(blog.tdm[1,1])
inspect(blog.tdm[1,1:2])
inspect(blog.tdm[1,1:5])
inspect(blog.tdm[1:5,1:5])
inspect(blog.tdm[10:15,1:5])
inspect(blog.tdm[100:115,1:5])
removePunctuation
text <- "my sister-in-law?,came isn't today!"
x <- gsub('!"#$%&()*+,\./:;<=>?@[\\\]^_`{|}~', " ", text)
x <- gsub('!"#$%&()*+,\\./:;<=>?@[\\\]^_`{|}~', " ", text)
x <- gsub('!"#$%&()*+,\\./:;<=>?@[]^_`{|}~', " ", text)
x <- gsub("([.-])|[[:punct:]]", "\\1", text)
x
text
text
text <- "my sister-in-law?,said \"no\" isn't today!"
x <- gsub("([-])|[[:punct:]]", "\\1", text)
x
x <- gsub("([-'])|[[:punct:]]", "\\1", text)
x
gsub("[st]"," ",text)
